import os
import re
import requests
from urllib.parse import urlparse

# ğŸ’¾ Lokasi file CSS
CSS_FILE = "./css/styles.css"  # cukup tulis nama file atau path relatif

# ğŸ“‚ Folder tempat menyimpan hasil download
OUTPUT_DIR = "output"

# ğŸ” Baca isi file CSS
with open(CSS_FILE, "r", encoding="utf-8") as f:
    css_content = f.read()

# ğŸ¯ Temukan semua URL dari file CSS
urls = re.findall(r'url\((?:["\']?)(https?://[^)"\']+)(?:["\']?)\)', css_content)
print(f"ğŸ¯ Ditemukan {len(urls)} file di {CSS_FILE}\n")

# ğŸ§  Hapus duplikat
urls = list(set(urls))

for url in urls:
    try:
        # Pisahkan path dari URL
        parsed = urlparse(url)
        path = parsed.path.lstrip("/")
        local_path = os.path.join(OUTPUT_DIR, path)

        # Pastikan folder tujuan ada
        os.makedirs(os.path.dirname(local_path), exist_ok=True)

        # Download file
        response = requests.get(url, timeout=15)
        if response.status_code == 200:
            with open(local_path, "wb") as f:
                f.write(response.content)
            print(f"âœ… {url} -> {local_path}")
        else:
            print(f"âš ï¸ Gagal ({response.status_code}): {url}")

    except Exception as e:
        print(f"âŒ Error: {url}\n   {e}")

print("\nğŸ‰ Semua file selesai diproses!")
